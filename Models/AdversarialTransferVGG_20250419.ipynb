{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89c4f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d73ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda...\n"
     ]
    }
   ],
   "source": [
    "# device\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Running on: {device}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40f4c1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter\n",
    "batch_size=20\n",
    "num_epochs=50\n",
    "lr=1e-4\n",
    "class_size=10\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b027f915",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e1a237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([transforms.Resize((224,224)),                                     \n",
    "                                     transforms.RandomHorizontalFlip(), \n",
    "                                     transforms.ToTensor(), \n",
    "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                                          std=[0.229, 0.224, 0.225])])\n",
    "transform_test = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                     transforms.ToTensor(), \n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                                         std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "#prep the train, validation and test dataset\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(\"data/\", train=True, \n",
    "                                     download=True, \n",
    "                                     transform=transform_train) \n",
    "\n",
    "combined_test_data = torchvision.datasets.CIFAR10(\"data/\", train=False, \n",
    "                                    download=True, \n",
    "                                    transform=transform_test) \n",
    "\n",
    "# Get targets from the test data for stratification\n",
    "targets = combined_test_data.targets\n",
    "\n",
    "# Stratified split for validation and test sets from the original test dataset\n",
    "sss_test_valid = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)  # Split 50/50\n",
    "valid_idx, test_idx = next(sss_test_valid.split(np.zeros(len(targets)), targets))\n",
    "\n",
    "# Convert indices to actual Subset for validation and test datasets\n",
    "valid_data = Subset(combined_test_data, valid_idx)\n",
    "test_data = Subset(combined_test_data, test_idx)\n",
    "\n",
    "\n",
    "#  train, val and test datasets to the dataloader\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "# specify the image classes\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8d2278",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c8dbce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16_NET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16_NET, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv8 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv9 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv10 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv11 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv12 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv13 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc14 = nn.Linear(25088, 4096)\n",
    "        self.fc15 = nn.Linear(4096, 4096)\n",
    "        self.fc16 = nn.Linear(4096, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv8(x))\n",
    "        x = F.relu(self.conv9(x))\n",
    "        x = F.relu(self.conv10(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv11(x))\n",
    "        x = F.relu(self.conv12(x))\n",
    "        x = F.relu(self.conv13(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = F.relu(self.fc14(x))\n",
    "        x = F.dropout(x, 0.5) #dropout was included to combat overfitting\n",
    "        x = F.relu(self.fc15(x))\n",
    "        x = F.dropout(x, 0.5)\n",
    "        x = self.fc16(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab347af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "VGG16 = VGG16_NET() \n",
    "\n",
    "\n",
    "VGG16.load_state_dict(torch.load('VGG16_20250420.pt', map_location=device))\n",
    "VGG16.to(device)\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef48bbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a random patch\n",
    "def create_patch(patch_size=(3, 3)):\n",
    "    patch = torch.randn(3, *patch_size, requires_grad=True, device=device)\n",
    "    return patch\n",
    "# Function to apply the patch to images\n",
    "def place_patch(img, patch):\n",
    "    batch_size, _, h, w = img.size()\n",
    "    ph, pw = patch.size(1), patch.size(2)\n",
    "    for i in range(batch_size):\n",
    "        x_offset = torch.randint(0, h - ph + 1, (1,)).item()\n",
    "        y_offset = torch.randint(0, w - pw + 1, (1,)).item()\n",
    "        img[i, :, x_offset:x_offset+ph, y_offset:y_offset+pw] = patch\n",
    "    return img\n",
    "# Function to evaluate the success rate of the adversarial patch\n",
    "def evaluate_patch(model, patch, dataloader, target_class=None):\n",
    "    model.eval()\n",
    "    success = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            patched_images = place_patch(images, patch)\n",
    "            outputs = model(patched_images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            if target_class is not None:\n",
    "                success += (predicted == target_class).sum().item()\n",
    "            else:\n",
    "                success += (predicted != labels).sum().item()  # Evaluate untargeted attack\n",
    "            total += labels.size(0)\n",
    "\n",
    "    successR = 100 * success / total\n",
    "    print(f\"Attack Success Rate: {successR:.2f}%\")\n",
    "    return successR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "782ae450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating untargeted adversarial patch, size: (3, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Success Rate: 20.66%\n",
      "\n",
      "Evaluating untargeted adversarial patch, size: (5, 5)\n",
      "Attack Success Rate: 20.24%\n",
      "\n",
      "Evaluating untargeted adversarial patch, size: (7, 7)\n",
      "Attack Success Rate: 23.56%\n",
      "\n",
      "Evaluating untargeted adversarial patch, size: (16, 16)\n",
      "Attack Success Rate: 30.18%\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-10 class names\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Different patch sizes\n",
    "patch_sizes = [(3, 3), (5, 5), (7, 7), (16, 16)]\n",
    "\n",
    "# Evaluate patches of different sizes\n",
    "for patch_size in patch_sizes:\n",
    "    \n",
    "    print(f\"\\nEvaluating untargeted adversarial patch, size: {patch_size}\")\n",
    "    patch = create_patch(patch_size)\n",
    "    patch = torch.load(f'adversarial_patch_{patch_size[0]}x{patch_size[1]}_untargeted.pth')\n",
    "    # Evaluate attack success rate\n",
    "    evaluate_patch(VGG16, patch, test_loader, target_class=None)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be9908b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating targeted adversarial patch (car), size: (3, 3)\n",
      "Attack Success Rate: 10.42%\n",
      "\n",
      "Evaluating targeted adversarial patch (car), size: (5, 5)\n",
      "Attack Success Rate: 11.04%\n",
      "\n",
      "Evaluating targeted adversarial patch (car), size: (7, 7)\n",
      "Attack Success Rate: 10.80%\n",
      "\n",
      "Evaluating targeted adversarial patch (car), size: (16, 16)\n",
      "Attack Success Rate: 11.62%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate patches of different sizes\n",
    "for patch_size in patch_sizes:\n",
    "    \n",
    "    print(f\"\\nEvaluating targeted adversarial patch (car), size: {patch_size}\")\n",
    "    patch = create_patch(patch_size)\n",
    "    patch = torch.load(f'adversarial_patch_{patch_size[0]}x{patch_size[1]}_targeted_car.pth')\n",
    "    # Evaluate attack success rate\n",
    "    evaluate_patch(VGG16, patch, test_loader, target_class=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
